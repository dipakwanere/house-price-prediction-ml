{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis â€” Kaggle House Prices (Advanced Regression Techniques)\n",
        "\n",
        "This notebook explores the Kaggle House Prices competition dataset. It documents columns, distributions, missingness, feature engineering ideas, and baseline modeling.\n",
        "\n",
        "- Load train/test via Kaggle files (train.csv, test.csv)\n",
        "- Column dictionary (from data_description.txt)\n",
        "- Missing values overview and imputation plan\n",
        "- Numeric distributions and outliers\n",
        "- Categorical levels and frequency\n",
        "- Correlations with SalePrice, log-transform check\n",
        "- Baseline model sanity check\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation: We load train/test CSVs and print shapes. Shape reports (rows, columns). Train has target `SalePrice`. We'll use `data_description.txt` for column meanings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation: dtypes tell us which columns are numeric vs categorical. Missingness guides imputation strategy. Memory helps gauge feasibility for models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[EDA] Data missing; invoking downloader...\n",
            "[EDA] Download attempt failed: Command '['c:\\\\z_DRIVEs\\\\ML_MLOps_Projects_2025\\\\Portfolio_project\\\\.venv\\\\Scripts\\\\python.exe', 'c:\\\\z_DRIVEs\\\\ML_MLOps_Projects_2025\\\\Portfolio_project\\\\notebooks\\\\scripts\\\\download_kaggle.py']' returned non-zero exit status 2.\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "Missing data/raw/train.csv even after download attempt. Ensure Kaggle auth and run scripts/download_kaggle.py",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m[EDA] Download attempt failed:\u001b[39m\u001b[33m'\u001b[39m, e)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m train_path.exists():\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mMissing data/raw/train.csv even after download attempt. Ensure Kaggle auth and run scripts/download_kaggle.py\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     29\u001b[39m train_df = pd.read_csv(train_path)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m test_path.exists():\n",
            "\u001b[31mFileNotFoundError\u001b[39m: Missing data/raw/train.csv even after download attempt. Ensure Kaggle auth and run scripts/download_kaggle.py"
          ]
        }
      ],
      "source": [
        "# Setup (auto-download if missing)\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "DATA_DIR = Path('data') / 'raw'\n",
        "train_path = DATA_DIR / 'train.csv'\n",
        "test_path = DATA_DIR / 'test.csv'\n",
        "desc_path = DATA_DIR / 'data_description.txt'\n",
        "\n",
        "if not train_path.exists() or not test_path.exists():\n",
        "    proj_kaggle = ROOT / '.kaggle' / 'kaggle.json'\n",
        "    if proj_kaggle.exists():\n",
        "        os.environ['KAGGLE_CONFIG_DIR'] = str(proj_kaggle.parent)\n",
        "    try:\n",
        "        print('[EDA] Data missing; invoking downloader...')\n",
        "        subprocess.check_call([sys.executable, str(ROOT / 'scripts' / 'download_kaggle.py')])\n",
        "    except Exception as e:\n",
        "        print('[EDA] Download attempt failed:', e)\n",
        "\n",
        "if not train_path.exists():\n",
        "    raise FileNotFoundError('Missing data/raw/train.csv even after download attempt. Ensure Kaggle auth and run scripts/download_kaggle.py')\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "if test_path.exists():\n",
        "    test_df = pd.read_csv(test_path)\n",
        "else:\n",
        "    test_df = pd.DataFrame()\n",
        "\n",
        "print('Train shape:', train_df.shape)\n",
        "print('Test shape:', test_df.shape)\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dataset overview: dtypes and memory\u001b[39;00m\n\u001b[32m      2\u001b[39m info = pd.DataFrame({\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mtrain_df\u001b[49m.dtypes.astype(\u001b[38;5;28mstr\u001b[39m),\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_missing\u001b[39m\u001b[33m'\u001b[39m: train_df.isna().sum(),\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpct_missing\u001b[39m\u001b[33m'\u001b[39m: (train_df.isna().mean()*\u001b[32m100\u001b[39m).round(\u001b[32m2\u001b[39m),\n\u001b[32m      6\u001b[39m })\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTotal rows:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_df), \u001b[33m'\u001b[39m\u001b[33m| Total columns:\u001b[39m\u001b[33m'\u001b[39m, train_df.shape[\u001b[32m1\u001b[39m])\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mApprox memory (MB):\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mround\u001b[39m(train_df.memory_usage(deep=\u001b[38;5;28;01mTrue\u001b[39;00m).sum() / \u001b[32m1e6\u001b[39m, \u001b[32m2\u001b[39m))\n",
            "\u001b[31mNameError\u001b[39m: name 'train_df' is not defined"
          ]
        }
      ],
      "source": [
        "# Dataset overview: dtypes and memory\n",
        "info = pd.DataFrame({\n",
        "    'dtype': train_df.dtypes.astype(str),\n",
        "    'n_missing': train_df.isna().sum(),\n",
        "    'pct_missing': (train_df.isna().mean()*100).round(2),\n",
        "})\n",
        "print('Total rows:', len(train_df), '| Total columns:', train_df.shape[1])\n",
        "print('Approx memory (MB):', round(train_df.memory_usage(deep=True).sum() / 1e6, 2))\n",
        "info.head(20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation: Parsed `data_description.txt` to map feature names to meanings. We'll display a sample of the dictionary to help readers understand each column.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation: `SalePrice` is right-skewed; `log1p` often stabilizes variance and improves linear modeling performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation: We inspect top numeric correlations. High absolute correlation with `SalePrice` suggests strong linear association; beware multicollinearity among predictors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation: Cardinality shows how many unique categories per feature. Very high cardinality may require special handling to avoid sparse explosions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation: Quick baseline with RF + preprocessing shows achievable performance without tuning. Use this as a yardstick for future improvements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Column-wise summary: name, dtype, missing %, description (if available)\n",
        "cols = []\n",
        "for col in train_df.columns:\n",
        "    cols.append({\n",
        "        'column': col,\n",
        "        'dtype': str(train_df[col].dtype),\n",
        "        'pct_missing': float(train_df[col].isna().mean()*100),\n",
        "        'description': col_desc.get(col, '')\n",
        "    })\n",
        "import pandas as pd\n",
        "col_info = pd.DataFrame(cols).sort_values('column')\n",
        "col_info.head(25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize top missingness\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "mis = train_df.isna().mean().sort_values(ascending=False)\n",
        "mis_top = mis[mis>0].head(20)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=mis_top.values*100, y=mis_top.index, color=\"#4f8cff\")\n",
        "plt.xlabel('% missing')\n",
        "plt.ylabel('feature')\n",
        "plt.title('Top 20 features by missingness')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation: The bar chart highlights which features need attention for imputation. High-missingness columns may be dropped or encoded carefully depending on importance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export full column summary for sharing\n",
        "export_path = Path('artifacts') / 'column_summary.csv'\n",
        "export_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "col_info.to_csv(export_path, index=False)\n",
        "export_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explanation: This table can be exported to share with stakeholders; it consolidates column meanings, types, and missingness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MedInc</th>\n",
              "      <td>20640.0</td>\n",
              "      <td>3.870671</td>\n",
              "      <td>1.899822</td>\n",
              "      <td>0.499900</td>\n",
              "      <td>2.563400</td>\n",
              "      <td>3.534800</td>\n",
              "      <td>4.743250</td>\n",
              "      <td>15.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HouseAge</th>\n",
              "      <td>20640.0</td>\n",
              "      <td>28.639486</td>\n",
              "      <td>12.585558</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>52.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AveRooms</th>\n",
              "      <td>20640.0</td>\n",
              "      <td>5.429000</td>\n",
              "      <td>2.474173</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>4.440716</td>\n",
              "      <td>5.229129</td>\n",
              "      <td>6.052381</td>\n",
              "      <td>141.909091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AveBedrms</th>\n",
              "      <td>20640.0</td>\n",
              "      <td>1.096675</td>\n",
              "      <td>0.473911</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.006079</td>\n",
              "      <td>1.048780</td>\n",
              "      <td>1.099526</td>\n",
              "      <td>34.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Population</th>\n",
              "      <td>20640.0</td>\n",
              "      <td>1425.476744</td>\n",
              "      <td>1132.462122</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>787.000000</td>\n",
              "      <td>1166.000000</td>\n",
              "      <td>1725.000000</td>\n",
              "      <td>35682.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AveOccup</th>\n",
              "      <td>20640.0</td>\n",
              "      <td>3.070655</td>\n",
              "      <td>10.386050</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>2.429741</td>\n",
              "      <td>2.818116</td>\n",
              "      <td>3.282261</td>\n",
              "      <td>1243.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Latitude</th>\n",
              "      <td>20640.0</td>\n",
              "      <td>35.631861</td>\n",
              "      <td>2.135952</td>\n",
              "      <td>32.540000</td>\n",
              "      <td>33.930000</td>\n",
              "      <td>34.260000</td>\n",
              "      <td>37.710000</td>\n",
              "      <td>41.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Longitude</th>\n",
              "      <td>20640.0</td>\n",
              "      <td>-119.569704</td>\n",
              "      <td>2.003532</td>\n",
              "      <td>-124.350000</td>\n",
              "      <td>-121.800000</td>\n",
              "      <td>-118.490000</td>\n",
              "      <td>-118.010000</td>\n",
              "      <td>-114.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MedHouseVal</th>\n",
              "      <td>20640.0</td>\n",
              "      <td>2.068558</td>\n",
              "      <td>1.153956</td>\n",
              "      <td>0.149990</td>\n",
              "      <td>1.196000</td>\n",
              "      <td>1.797000</td>\n",
              "      <td>2.647250</td>\n",
              "      <td>5.000010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MedHouseValUSD</th>\n",
              "      <td>20640.0</td>\n",
              "      <td>206855.816909</td>\n",
              "      <td>115395.615874</td>\n",
              "      <td>14999.000000</td>\n",
              "      <td>119600.000000</td>\n",
              "      <td>179700.000000</td>\n",
              "      <td>264725.000000</td>\n",
              "      <td>500001.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  count           mean            std           min  \\\n",
              "MedInc          20640.0       3.870671       1.899822      0.499900   \n",
              "HouseAge        20640.0      28.639486      12.585558      1.000000   \n",
              "AveRooms        20640.0       5.429000       2.474173      0.846154   \n",
              "AveBedrms       20640.0       1.096675       0.473911      0.333333   \n",
              "Population      20640.0    1425.476744    1132.462122      3.000000   \n",
              "AveOccup        20640.0       3.070655      10.386050      0.692308   \n",
              "Latitude        20640.0      35.631861       2.135952     32.540000   \n",
              "Longitude       20640.0    -119.569704       2.003532   -124.350000   \n",
              "MedHouseVal     20640.0       2.068558       1.153956      0.149990   \n",
              "MedHouseValUSD  20640.0  206855.816909  115395.615874  14999.000000   \n",
              "\n",
              "                          25%            50%            75%            max  \n",
              "MedInc               2.563400       3.534800       4.743250      15.000100  \n",
              "HouseAge            18.000000      29.000000      37.000000      52.000000  \n",
              "AveRooms             4.440716       5.229129       6.052381     141.909091  \n",
              "AveBedrms            1.006079       1.048780       1.099526      34.066667  \n",
              "Population         787.000000    1166.000000    1725.000000   35682.000000  \n",
              "AveOccup             2.429741       2.818116       3.282261    1243.333333  \n",
              "Latitude            33.930000      34.260000      37.710000      41.950000  \n",
              "Longitude         -121.800000    -118.490000    -118.010000    -114.310000  \n",
              "MedHouseVal          1.196000       1.797000       2.647250       5.000010  \n",
              "MedHouseValUSD  119600.000000  179700.000000  264725.000000  500001.000000  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summary statistics\n",
        "summary = train_df.describe().T\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MedHouseValUSD    1.000000\n",
              "MedHouseVal       1.000000\n",
              "MedInc            0.688075\n",
              "AveRooms          0.151948\n",
              "HouseAge          0.105623\n",
              "AveOccup         -0.023737\n",
              "Population       -0.024650\n",
              "Longitude        -0.045967\n",
              "AveBedrms        -0.046701\n",
              "Latitude         -0.144160\n",
              "Name: MedHouseValUSD, dtype: float64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Correlations with target\n",
        "corr = train_df.corr(numeric_only=True)\n",
        "corr['SalePrice'].sort_values(ascending=False).head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline LinearRegression -> MAE: 53,320 USD | R2: 0.576\n"
          ]
        }
      ],
      "source": [
        "# Missing values overview\n",
        "missing = train_df.isna().mean().sort_values(ascending=False)\n",
        "missing[missing>0].head(30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Column dictionary from data_description.txt (parsed compactly)\n",
        "text = Path(desc_path).read_text(encoding='utf-8', errors='ignore')\n",
        "lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
        "# Heuristic parse: lines like 'MSSubClass: Identifies the type of dwelling involved in the sale.'\n",
        "col_desc = {}\n",
        "for ln in lines:\n",
        "    if ':' in ln and ln.split(':', 1)[0].strip().isidentifier():\n",
        "        k, v = ln.split(':', 1)\n",
        "        if len(k) <= 30:\n",
        "            col_desc[k.strip()] = v.strip()\n",
        "len(col_desc), list(col_desc.items())[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Target distribution (SalePrice) and log-transform check\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "sns.histplot(train_df['SalePrice'], kde=True, ax=axes[0])\n",
        "axes[0].set_title('SalePrice')\n",
        "sns.histplot(np.log1p(train_df['SalePrice']), kde=True, ax=axes[1])\n",
        "axes[1].set_title('log1p(SalePrice)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Numeric features correlation heatmap (top 20 by abs corr with SalePrice)\n",
        "num_corr = train_df.corr(numeric_only=True)['SalePrice'].abs().sort_values(ascending=False)\n",
        "top_cols = num_corr.head(20).index\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(train_df[top_cols].corr(), cmap='coolwarm', center=0, annot=False)\n",
        "plt.title('Top numeric correlations')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Categorical cardinality and top levels preview\n",
        "cat_cols = train_df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "card = train_df[cat_cols].nunique().sort_values(ascending=False)\n",
        "card.head(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline model: simple pipeline similar to training script\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from app.service.feature_engineering import build_preprocessing_pipeline\n",
        "\n",
        "# Train/valid split\n",
        "X = train_df.drop(columns=['SalePrice'])\n",
        "y = train_df['SalePrice']\n",
        "pre = build_preprocessing_pipeline(train_df)\n",
        "model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "from sklearn.pipeline import Pipeline\n",
        "pipe = Pipeline(steps=[('pre', pre), ('model', model)])\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "pipe.fit(X_tr, y_tr)\n",
        "preds = pipe.predict(X_va)\n",
        "print('MAE:', mean_absolute_error(y_va, preds))\n",
        "print('R2:', r2_score(y_va, preds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
